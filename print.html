<!DOCTYPE HTML>
<html lang="en" class="light" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Knowledge Base</title>
        <meta name="robots" content="noindex">


        <!-- Custom HTML head -->
        
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->

    </head>
    <body class="sidebar-visible no-js">
    <div id="body-container">
        <!-- Provide site root to javascript -->
        <script>
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('light')
            html.classList.add(theme);
            var body = document.querySelector('body');
            body.classList.remove('no-js')
            body.classList.add('js');
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            var body = document.querySelector('body');
            var sidebar = null;
            var sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
            }
            sidebar_toggle.checked = sidebar === 'visible';
            body.classList.remove('sidebar-visible');
            body.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded "><a href="index.html"><strong aria-hidden="true">1.</strong> Knowledge Base</a></li><li class="chapter-item expanded "><a href="SoftwareTesting/index.html"><strong aria-hidden="true">2.</strong> Software Testing</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="SoftwareTesting/srs.html"><strong aria-hidden="true">2.1.</strong> Software Requirements Specification</a></li><li class="chapter-item expanded "><a href="SoftwareTesting/white-box.html"><strong aria-hidden="true">2.2.</strong> White Box Testing</a></li><li class="chapter-item expanded "><a href="SoftwareTesting/black-box.html"><strong aria-hidden="true">2.3.</strong> Black Box Testing</a></li><li class="chapter-item expanded "><a href="SoftwareTesting/techniques.html"><strong aria-hidden="true">2.4.</strong> Techniques</a></li></ol></li><li class="chapter-item expanded "><a href="AdvancedOperatingSystems/index.html"><strong aria-hidden="true">3.</strong> Advanced Operating Systems</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="AdvancedOperatingSystems/booting.html"><strong aria-hidden="true">3.1.</strong> Booting</a></li><li class="chapter-item expanded "><a href="AdvancedOperatingSystems/memory.html"><strong aria-hidden="true">3.2.</strong> Memory</a></li><li class="chapter-item expanded "><a href="AdvancedOperatingSystems/page-tables.html"><strong aria-hidden="true">3.3.</strong> Page Tables</a></li><li class="chapter-item expanded "><a href="AdvancedOperatingSystems/user-mode.html"><strong aria-hidden="true">3.4.</strong> User Mode</a></li><li class="chapter-item expanded "><a href="AdvancedOperatingSystems/interrupts.html"><strong aria-hidden="true">3.5.</strong> Interrupts</a></li><li class="chapter-item expanded "><a href="AdvancedOperatingSystems/system-calls.html"><strong aria-hidden="true">3.6.</strong> System Calls</a></li><li class="chapter-item expanded "><a href="AdvancedOperatingSystems/paging.html"><strong aria-hidden="true">3.7.</strong> Paging</a></li><li class="chapter-item expanded "><a href="AdvancedOperatingSystems/multiprocessing.html"><strong aria-hidden="true">3.8.</strong> Multi-Processing</a></li><li class="chapter-item expanded "><a href="AdvancedOperatingSystems/multicore.html"><strong aria-hidden="true">3.9.</strong> Multi-Core</a></li></ol></li><li class="chapter-item expanded "><a href="HardwareSecurity/index.html"><strong aria-hidden="true">4.</strong> Hardware Security</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="HardwareSecurity/dram.html"><strong aria-hidden="true">4.1.</strong> DRAM</a></li></ol></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <!-- Track and set sidebar scroll position -->
        <script>
            var sidebarScrollbox = document.querySelector('#sidebar .sidebar-scrollbox');
            sidebarScrollbox.addEventListener('click', function(e) {
                if (e.target.tagName === 'A') {
                    sessionStorage.setItem('sidebar-scroll', sidebarScrollbox.scrollTop);
                }
            }, { passive: true });
            var sidebarScrollTop = sessionStorage.getItem('sidebar-scroll');
            sessionStorage.removeItem('sidebar-scroll');
            if (sidebarScrollTop) {
                // preserve sidebar scroll position when navigating via links within sidebar
                sidebarScrollbox.scrollTop = sidebarScrollTop;
            } else {
                // scroll sidebar to current active section when navigating via "next/previous chapter" buttons
                var activeSection = document.querySelector('#sidebar .active');
                if (activeSection) {
                    activeSection.scrollIntoView({ block: 'center' });
                }
            }
        </script>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">Knowledge Base</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="knowledge-base"><a class="header" href="#knowledge-base">Knowledge Base</a></h1>
<p>A hierarchically organized knowledge-base of things I am learning. Forever a <em>work in progress</em>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="software-testing"><a class="header" href="#software-testing">Software Testing</a></h1>
<p>Software Testing is closely coupled with Requirements Engineering and Software Verification, however this section mostly covers important testing techniques and construction of test plans as well as software requirements.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="srs"><a class="header" href="#srs">SRS</a></h1>
<p>An SRS document supplies the reader with all the necessary information to understand the Functional and Non-Functional Requirements. The following is a template:</p>
<h4 id="introduction"><a class="header" href="#introduction">Introduction</a></h4>
<ul>
<li>
<p><strong>Purpose</strong> -
Identify the product whose software requirements are specified in this document, including the
revision or release number. Describe the scope of the product that is covered by this SRS,
particularly if this SRS describes only part of the system or a single subsystem.</p>
</li>
<li>
<p><strong>Document Conventions</strong> -
Describe any standards or typographical conventions that were followed when writing this SRS,
such as fonts or highlighting that have special significance. For example, state whether priorities
for higher-level requirements are assumed to be inherited by detailed requirements, or whether
every requirement statement is to have its own priority.</p>
</li>
<li>
<p><strong>Intended Audience and Reading Suggestions</strong> -
Describe the different types of reader that the document is intended for, such as developers,
project managers, marketing staff, users, testers, and documentation writers. Describe what the
rest of this SRS contains and how it is organized. Suggest a sequence for reading the document,
beginning with the overview sections and proceeding through the sections that are most pertinent
to each reader type.</p>
</li>
<li>
<p><strong>Product Scope</strong> -
Provide a short description of the software being specified and its purpose, including relevant
benefits, objectives, and goals. Relate the software to corporate goals or business strategies. If a
separate vision and scope document is available, refer to it rather than duplicating its contents
here.</p>
</li>
<li>
<p><strong>References</strong> -
List any other documents or Web addresses to which this SRS refers. These may include user
interface style guides, contracts, standards, system requirements specifications, use case
documents, or a vision and scope document. Provide enough information so that the reader could
access a copy of each reference, including title, author, version number, date, and source or
location.</p>
</li>
</ul>
<h4 id="overall-description"><a class="header" href="#overall-description">Overall Description</a></h4>
<ul>
<li>
<p><strong>Product Perspective</strong> -
Describe the context and origin of the product being specified in this SRS. For example, state
whether this product is a follow-on member of a product family, a replacement for certain existing
systems, or a new, self-contained product. If the SRS defines a component of a larger system,
relate the requirements of the larger system to the functionality of this software and identify
interfaces between the two. A simple diagram that shows the major components of the overall
system, subsystem interconnections, and external interfaces can be helpful.</p>
</li>
<li>
<p><strong>Product Functions</strong> -
Summarize the major functions the product must perform or must let the user perform. Details
will be provided in Section 3, so only a high level summary (such as a bullet list) is needed here.
Organize the functions to make them understandable to any reader of the SRS. A picture of the
major groups of related requirements and how they relate, such as a top level data flow diagram
or object class diagram, is often effective.</p>
</li>
<li>
<p><strong>User Classes and Characteristics</strong> -
Identify the various user classes that you anticipate will use this product. User classes may be
differentiated based on frequency of use, subset of product functions used, technical expertise,
security or privilege levels, educational level, or experience. Describe the pertinent characteristics
of each user class. Certain requirements may pertain only to certain user classes. Distinguish the
most important user classes for this product from those who are less important to satisfy.</p>
</li>
<li>
<p><strong>Operating Environment</strong> -
Describe the environment in which the software will operate, including the hardware platform,
operating system and versions, and any other software components or applications with which it
must peacefully coexist.</p>
</li>
<li>
<p><strong>Design and Implementation Constraints</strong> -
Describe any items or issues that will limit the options available to the developers. These might
include: corporate or regulatory policies; hardware limitations (timing requirements, memory
requirements); interfaces to other applications; specific technologies, tools, and databases to be
used; parallel operations; language requirements; communications protocols; security
considerations; design conventions or programming standards (for example, if the customer’s
organization will be responsible for maintaining the delivered software).</p>
</li>
<li>
<p><strong>User Documentation</strong> -
List the user documentation components (such as user manuals, on-line help, and tutorials) that
will be delivered along with the software. Identify any known user documentation delivery formats
or standards.</p>
</li>
<li>
<p><strong>Assumptions and Dependencies</strong> -
List any assumed factors (as opposed to known facts) that could affect the requirements stated
in the SRS. These could include third-party or commercial components that you plan to use,
issues around the development or operating environment, or constraints. The project could be
affected if these assumptions are incorrect, are not shared, or change. Also identify any
dependencies the project has on external factors, such as software components that you intend
to reuse from another project, unless they are already documented elsewhere (for example, in the
vision and scope document or the project plan).</p>
</li>
</ul>
<h4 id="external-interface-requirements"><a class="header" href="#external-interface-requirements">External Interface Requirements</a></h4>
<ul>
<li>
<p><strong>User Interfaces</strong> -
Describe the logical characteristics of each interface between the software product and the
users. This may include sample screen images, any GUI standards or product family style guides
that are to be followed, screen layout constraints, standard buttons and functions (e.g., help) that
will appear on every screen, keyboard shortcuts, error message display standards, and so on.
Define the software components for which a user interface is needed. Details of the user interface
design should be documented in a separate user interface specification.</p>
</li>
<li>
<p><strong>Hardware Interfaces</strong> -
Describe the logical and physical characteristics of each interface between the software product
and the hardware components of the system. This may include the supported device types, the
nature of the data and control interactions between the software and the hardware, and
communication protocols to be used.</p>
</li>
<li>
<p><strong>Software Interfaces</strong> -
Describe the connections between this product and other specific software components (name
and version), including databases, operating systems, tools, libraries, and integrated commercial
components. Identify the data items or messages coming into the system and going out and
describe the purpose of each. Describe the services needed and the nature of communications.
Refer to documents that describe detailed application programming interface protocols. Identify
data that will be shared across software components. If the data sharing mechanism must be
implemented in a specific way (for example, use of a global data area in a multitasking operating
system), specify this as an implementation constraint.</p>
</li>
<li>
<p><strong>Communications Interfaces</strong> -
Describe the requirements associated with any communications functions required by this
product, including e-mail, web browser, network server communications protocols, electronic
forms, and so on. Define any pertinent message formatting. Identify any communication
standards that will be used, such as FTP or HTTP. Specify any communication security or
encryption issues, data transfer rates, and synchronization mechanisms.</p>
</li>
</ul>
<h4 id="system-features"><a class="header" href="#system-features">System Features</a></h4>
<ul>
<li><strong>System Feature 1</strong> -
<ul>
<li><strong>Description &amp; Priority</strong> -
Provide a short description of the feature and indicate whether it is of High,
Medium, or Low priority. You could also include specific priority component ratings,
such as benefit, penalty, cost, and risk (each rated on a relative scale from a low of
1 to a high of 9).</li>
<li><strong>Stimulus &amp; Response Sequences</strong> -
List the sequences of user actions and system responses that stimulate the
behavior defined for this feature. These will correspond to the dialog elements
associated with use cases.</li>
<li><strong>Functional Requirements</strong> -
Itemize the detailed functional requirements associated with this feature. These
are the software capabilities that must be present in order for the user to carry out
the services provided by the feature, or to execute the use case. Include how the
product should respond to anticipated error conditions or invalid inputs.
Requirements should be concise, complete, unambiguous, verifiable, and
necessary. Use “TBD” as a placeholder to indicate when necessary information is
not yet available.
<ul>
<li><strong>FR 1</strong> - ...</li>
<li><strong>FR 2</strong> - ...</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="other-nonfunctional-requirements"><a class="header" href="#other-nonfunctional-requirements">Other Nonfunctional Requirements</a></h4>
<ul>
<li>
<p><strong>Performance Requirements</strong> -
If there are performance requirements for the product under various circumstances, state them
here and explain their rationale, to help the developers understand the intent and make suitable
design choices. Specify the timing relationships for real time systems. Make such requirements as
specific as possible. You may need to state performance requirements for individual functional
requirements or features.</p>
</li>
<li>
<p><strong>Safety Requirements</strong> -
Specify those requirements that are concerned with possible loss, damage, or harm that could
result from the use of the product. Define any safeguards or actions that must be taken, as well
as actions that must be prevented. Refer to any external policies or regulations that state safety
issues that affect the product’s design or use. Define any safety certifications that must be
satisfied.</p>
</li>
<li>
<p><strong>Security Requirements</strong> -
Specify any requirements regarding security or privacy issues surrounding use of the product or
protection of the data used or created by the product. Define any user identity authentication
requirements. Refer to any external policies or regulations containing security issues that affect
the product. Define any security or privacy certifications that must be satisfied.</p>
</li>
<li>
<p><strong>Software Quality Attributes</strong> -
Specify any additional quality characteristics for the product that will be important to either the
customers or the developers. Some to consider are: adaptability, availability, correctness,
flexibility, interoperability, maintainability, portability, reliability, reusability, robustness, testability,
and usability. Write these to be specific, quantitative, and verifiable when possible. At the least,
clarify the relative preferences for various attributes, such as ease of use over ease of learning.</p>
</li>
<li>
<p><strong>Business Rules</strong> -
List any operating principles about the product, such as which individuals or roles can perform
which functions under specific circumstances. These are not functional requirements in
themselves, but they may imply certain functional requirements to enforce the rules.</p>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="white-box-testing"><a class="header" href="#white-box-testing">White-Box Testing</a></h1>
<p>Performing tests on software with the source code available. Generally, one should follow the following methodology:</p>
<ol>
<li>Make a prioritized list of your "nightmares".</li>
<li>Which bugs can lead to the nightmares?</li>
<li>Apply testing techniques that are best suited for detecting these bugs.</li>
<li>Gather enough evidence to that there the likelihood of a nightmare scenario is negligible, at which point stop testing.</li>
</ol>
<p>Static Analysis is one of the most powerful tools, leveraging compilers and linting is a must.</p>
<h3 id="control-flow-testing"><a class="header" href="#control-flow-testing">Control-Flow Testing</a></h3>
<p>Testing coverage is a measure of completeness of the set of test cases and shows how much code has been exercised during testing.</p>
<ul>
<li>
<p><strong>Level 1 Statement Coverage</strong> - Weakest criteria, ensures that every statement in code has been executed at least once.</p>
</li>
<li>
<p><strong>Level 2 Decision Coverage</strong> - Ensures that the decision of all branches has been taken at least once. Includes statement coverage.</p>
</li>
<li>
<p><strong>Level 3 Condition Coverage</strong> - Ensures that every "simple" condition has been evaluated with both true and false. This doesn't mean that all "composite" conditions have been extensively evaluated.</p>
</li>
<li>
<p><strong>Level 4 Decision/Condition Coverage</strong> - All conditions and decisions is evaluated with both values. In this case decisions can be the composition of multiple conditions.</p>
</li>
<li>
<p><strong>Level 5 Multiple Condition Coverage</strong> - Requires that all combinations of "simple" conditions are covered.</p>
</li>
<li>
<p><strong>Level 6 Modified Condition/Decision Coverage</strong> - Requires that all decisions have been covered, that all simple conditions have been evaluated with both true and false, and that each simple condition within all compound conditions has been shown to independently effect outcome of the compound condition.</p>
</li>
<li>
<p><strong>Level 7 Full Path Coverage</strong> - Fully exhaustive white box testing, but tends to be infeasible.</p>
</li>
</ul>
<h3 id="data-flow-testing"><a class="header" href="#data-flow-testing">Data-Flow Testing</a></h3>
<p>The aim is to trim the set of test cases that we are interested in. Increases the chance of spending more time looking at paths that include potential software faults.</p>
<ul>
<li>All <em>Def-Use</em> Paths: test cases must exercise all paths that involve a definition and use of variables of interest.</li>
</ul>
<h3 id="test-adequacy"><a class="header" href="#test-adequacy">Test Adequacy</a></h3>
<p>When has a program been sufficiently tested? A test adequacy criterion such as Mutant Score, reveals how well our test cases are performing.</p>
<blockquote>
<p><strong>Definition:</strong>
A code mutant is a version of the software under test that underwent some form of mutation, for example, arithmetic operators have been replaced.</p>
</blockquote>
<p>Mutants can survive if their output is correct for any given test case. Survivors are analyzed to improve test cases. However, some (equivalent) mutants might never be killed. Mutant Score is defined as <code>#killed_mutants / #total_mutants</code>.</p>
<h3 id="unit-testing"><a class="header" href="#unit-testing">Unit Testing</a></h3>
<p>Testing an individual module / component of a system. In practice, this is testing of a single method or class. <a href="https://en.wikipedia.org/wiki/Unit_testing">(wiki)</a></p>
<h3 id="integration-testing"><a class="header" href="#integration-testing">Integration Testing</a></h3>
<p>Testing the multiple parts of the system as a group. Typically it follows after modules have been unit tested. <a href="https://en.wikipedia.org/wiki/Integration_testing">(wiki)</a></p>
<ul>
<li><em>big-bang</em> - modules are coupled together to form a complete system that is tested</li>
<li><em>top-down</em> - start with highest level module and then test step by step down incrementally</li>
<li><em>bottom-up</em> - start with the lowest level module, test your way up by integrating</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="black-box-testing"><a class="header" href="#black-box-testing">Black Box Testing</a></h1>
<p>Testing when the source code is not available.</p>
<h1 id="techniques"><a class="header" href="#techniques">Techniques</a></h1>
<h3 id="bva---boundary-value-analysis"><a class="header" href="#bva---boundary-value-analysis">BVA - Boundary Value Analysis</a></h3>
<p>For mechanisms that have input ranges, apply test cases that position themselves at the boundaries of those ranges. For each of the following test just above and just below:</p>
<ul>
<li>min</li>
<li>nominal</li>
<li>max</li>
</ul>
<h3 id="ep---equivalence-partitioning"><a class="header" href="#ep---equivalence-partitioning">EP - Equivalence Partitioning</a></h3>
<p>If the program creates classes from the input, make sure all classes are represented. Can be done by finding representative values in the input domain or the output domain. If there are multiple input variables there are the following:</p>
<ul>
<li>Unidimensional partition - only focus on one variable at a time and ignore the others.</li>
<li>Multidimensional partition - test all variables in all possible combinations</li>
</ul>
<h3 id="mbt---model-based-testing"><a class="header" href="#mbt---model-based-testing">MBT - Model Based Testing</a></h3>
<p>A model is made from requirements and generates test cases. Use different notations such as pre/post conditions.</p>
<ul>
<li>
<p>Input domain models: Combinatorial Design</p>
<ul>
<li>assist the design of the test cases and offer a significant reduction in the number of test cases</li>
</ul>
</li>
<li>
<p>Input domain models: Syntax Testing</p>
<ul>
<li>used to verify that a module that accepts input from another module does not fail when presented ill-formed input</li>
<li>The syntax is the model of the input, Inputs are specified in SRS using a grammar or a context-free language</li>
<li>used to test compilers!</li>
</ul>
</li>
<li>
<p>Behavior Models:</p>
<ul>
<li>Test the use cases, capture system's functional requirements from user's perspective</li>
<li>Decision Tables - used to concisely and completely show complex rules and their resulting actions: test cases can be
<ul>
<li>at least one test case for each rule</li>
<li>if the rule is a range of values combine DT and BVA</li>
</ul>
</li>
<li>Cause-effect graphs / dependency modeling - design test cases for functions that depend on a combination of more input items</li>
<li>State Machines - test cases should:
<ul>
<li>visit all states</li>
<li>trigger all events at least once</li>
<li>exercise all transitions</li>
<li>execute all paths at least once</li>
</ul>
</li>
</ul>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="software-correctness"><a class="header" href="#software-correctness">Software Correctness</a></h1>
<p>The following is an enumeration of several methods in which one can assert correctness properties of software.</p>
<h2 id="writing-documentation"><a class="header" href="#writing-documentation">Writing Documentation</a></h2>
<p>The first step in removing bugs is documenting the code itself. Using tools like <code>rustdoc</code> will run code that is part of the documentation as test. Handy for testing the public API.</p>
<h2 id="unit--integration-testing"><a class="header" href="#unit--integration-testing">Unit &amp; Integration Testing</a></h2>
<p>Traditional testing places lots of the work and pressure on the programmer themselves to make sure they cover all test cases. For test driven development, this is very useful and should generally always be used a starting point to ensure basic working functionality. Using native tooling such as <code>cargo test</code> allows for easy integration with existing code. Creating unit tests helps with checking basic correctness at a function-level granularity. Then, integration tests can be used once modules are combined together and tested in conjunction. Typically, integration tests target the API surface. Test coverage can be used as a metric to see how much of the code was tested (<code>cargo-llvm-cov</code>). These are the <em>bare</em> minimum.</p>
<h2 id="mutation-testing"><a class="header" href="#mutation-testing">Mutation Testing</a></h2>
<p>Given an existing test suite, the mutation of the source code should prevent the tests from passing. If the tests continue to pass despite the source code being mutated, there are either not enough tests, they are incorrect or there is a bug. Tools for this include <code>cargo mutants</code> and <code>mutagen</code>.</p>
<h2 id="fuzz-testing"><a class="header" href="#fuzz-testing">Fuzz Testing</a></h2>
<p>Fuzzing stress tests the program crafting many randomly generated inputs. Typically, fuzzers are setup such that they track which parts of the program they have reached, and can then try to favor inputs that get reach new code. Coverage is a commonly used metric to navigate the fuzzer, however this is a field under active research. If this technique can be easily adapted by frameworks like <code>cargo-fuzz</code> and <code>libAfl</code> it can be an incredibly effective method of discovering less obvious bugs.</p>
<h2 id="property-testing"><a class="header" href="#property-testing">Property Testing</a></h2>
<p>Property testing generates random inputs based on predefined properties or constraints. It is up to the tester to implement the properties and constraints correctly. Property testing is probabilistic and doesn't test the entire input space. It applies shrinking on the input which involves searching the input space of combinations for a smallest possible example of a failing test case. Commonly used frameworks for protesting are <code>proptest</code> and <code>quickcheck</code>.</p>
<h2 id="model-checking"><a class="header" href="#model-checking">Model Checking</a></h2>
<p><em>todo</em></p>
<h2 id="deductive-verification"><a class="header" href="#deductive-verification">Deductive Verification</a></h2>
<p><em>todo</em></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="advanced-operating-systems"><a class="header" href="#advanced-operating-systems">Advanced Operating Systems</a></h1>
<p>An operating system is comprised of many layers of abstraction where each layer generally takes on a different responsibility. At the lowest level is the <strong>kernel</strong> which interacts directly with the hardware and runs with the highest level of privilege. Then the kernel is wrapped in a <em>"shell"</em> of <strong>system software</strong>. These are user space programs that interact with the kernel and provide critical functionality. Lastly, there is an optional <strong>desktop environment</strong> that provides a graphical user interface, if the OS is being used directly by end users.</p>
<pre><code>     +--------------------------+
     |   Desktop Environment    |
     |  +--------------------+  |
     |  |  System Software   |  |
     |  |  +--------------+  |  |
     |  |  |    Kernel    |  |  |
     |  |  | +----------+ |  |  |
     |  |  | | Hardware | |  |  |
     +--------------------------+
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="genesis-x86-64"><a class="header" href="#genesis-x86-64">Genesis (x86-64)</a></h1>
<p>After pressing the power on button:</p>
<ol>
<li>CPU executes code in ROM.</li>
<li>Loads firmware BIOS, UEFI, Coreboot, OpenFirmware into memory</li>
<li>Initializes memory and other devices</li>
<li>Loads boot code into memory, traditionally first sector was boot code</li>
</ol>
<p>Traditional <strong>two-stage bootloader</strong> is there for historical reasons, since there were only 512bytes available for the first boot section. Thus, it must simply load the second stage boot code with more memory available.</p>
<h1 id="questions"><a class="header" href="#questions">Questions</a></h1>
<ul>
<li>When booting why is it required to go through all modes?</li>
<li>How is ROM code updated on older hardware?</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="physical-memory"><a class="header" href="#physical-memory">Physical Memory</a></h1>
<p>The memory controller communicates on the BUS over different channels (usually 1 / 2), but only one <strong>channel</strong> can be active at a time. For each channel there are physical memory modules (<a href="https://en.wikipedia.org/wiki/DIMM">DIMMs</a>). One side of the <strong>DIMM</strong> is a <strong>rank</strong>, typically 1/2 ranks per DIMM. Each rank has a <strong>chip</strong>, with a number of <strong>rows and columns</strong>.</p>
<p>Linux organizes memory into consecutive page frames and grouped together in the following way:</p>
<ul>
<li>Nodes - <a href="https://en.wikipedia.org/wiki/Non-uniform_memory_access">NUMA</a> abstraction for N "banks"</li>
<li>Zones - tagged regions within each node</li>
<li>Pages - Physical page frames from each zone</li>
</ul>
<p>Linux Zone ranges:</p>
<ul>
<li>ZONE_DMA: 0 - 16MB <em>for legacy hardware</em></li>
<li>ZONE_DMA32: 16MB - 4GB <em>for legacy hardware</em></li>
<li>ZONE_NORMAL: 16MB - 896MB <em>for kernel - always mapped</em></li>
<li>ZONE_HIGHMEM: 896MB - END <em>used for kmap, on demand memory mapping x86</em></li>
</ul>
<p>Zones are managed independently, however boundaries become blurry when under pressure. Kernel daemon kswapd will reclaim memory when certain thresholds are crossed. Virtual memory mapping on x86-32 starts ZONE_DMA and ZONE_NORMAL directly after the PAGE_OFFSET and ZONE_HIGHMEM is mapped on demand. The PAGE_OFFSET is where the user space processes start. However, for x86-64 there are 47 bits of memory address space available, so it can simply map all zones into one continuous region.</p>
<h2 id="pages"><a class="header" href="#pages">Pages</a></h2>
<ul>
<li>4KB of physical memory</li>
<li><code>linux/mmzone.h</code> has mem_map array which holds page objects</li>
</ul>
<h1 id="allocators"><a class="header" href="#allocators">Allocators</a></h1>
<p>Linux has one main page allocator (Buddy allocator) which allocates contiguous areas of physical memory. All allocators custom to the kernel from different subsystems interact with it. The Memblock allocator is an early boot-time allocator, discarded after initialization and contains two simple data structures: all present memory and allocated memory regions. Memblock has the following procedures:</p>
<p>Setup: add all available physical memory regions, add reserved to reserved list, sort by base address
Allocation: first fit memory, add to reserved list and merge neighbors if possible
De-allocation: scans reserved list, split up regions if necessary</p>
<h2 id="memblock-boot-allocator"><a class="header" href="#memblock-boot-allocator">Memblock Boot Allocator</a></h2>
<p>Can only allocate memory and maintains an index to the next free block. It's essentially just one long array of bytes.</p>
<h2 id="buddy-allocator"><a class="header" href="#buddy-allocator">Buddy Allocator</a></h2>
<p>Power of two allocator with free coalescing. During allocation, requested size will go into a block that satisfies the size, unused remainders are inevitable. During de-allocation, neighboring buddy block is checked and coalesced if it is free (recursively). MAX_ORDER in linux specifies a power of two coefficient for the maximum number of orders (levels). Works at a per-zone separation.</p>
<h1 id="vmalloc-vs-slab-allocator"><a class="header" href="#vmalloc-vs-slab-allocator">vmalloc vs slab allocator</a></h1>
<ul>
<li>vmalloc
<ul>
<li>plugs in small holes and prevents external fragmentation</li>
<li>is better for very large allocations, since buddy/slab will then cause more external fragmentation</li>
<li>is slower than slab</li>
<li>uses non-contiguous physical memory</li>
<li>has its own range</li>
</ul>
</li>
<li>slab allocator
<ul>
<li>is very fast, since it uses a cache</li>
<li>uses contiguous physical memory</li>
</ul>
</li>
</ul>
<h3 id="fragmentation"><a class="header" href="#fragmentation">Fragmentation</a></h3>
<ul>
<li><strong>External fragmentation</strong> When a request for a large amount of memory comes in, although there might be enough memory for it, it is unable to be allocated due to many disjoint holes of unallocated space.
<ul>
<li>Solved by the <code>vmalloc</code> allocator which sits on top of buddy allocator for large allocations, uses first-fit technique and maps page frames in virtually continuous buffer to scattered pages across physical memory. Allocates a single page from the buddy allocator at a time.</li>
</ul>
</li>
<li><strong>Internal fragmentation</strong> Allocations smaller than 4Kb will always have wasted space, as well as when requests are just above the closest power of two.
<ul>
<li>Addressed with the <code>slab</code> allocator which also sits on top of buddy allocator. For small allocations, continuous in virtual memory as well as physical memory</li>
</ul>
</li>
</ul>
<h3 id="sanity-checks-during-development"><a class="header" href="#sanity-checks-during-development">Sanity Checks during development</a></h3>
<ul>
<li><code>CONFIG_DEBUG_PAGEALLOC</code>
<ol>
<li>Out of bounds detection, adds page guards before and after page which limits how far out of bounds accesses can go. Page canaries will be changed if magic value is changed are also possible.</li>
<li>Use after free detection (<code>kernel_map_pages</code>) simply unmaps virtual memory interrupt handled by MMU, accept for when it is reused again. Can also use page poisoning which lets us lazily detect write-after-frees, however also after page is reused, no longer protected</li>
<li><code>kmemcheck</code> - traps at every read to check if data is initialized, very expensive</li>
<li><code>kmemleak</code> - periodic garbage collection, reports about unlinked objects, false positives can happen</li>
<li><code>kasan</code> - compiler instrumentation, adds combines canary and poison ideas</li>
</ol>
</li>
<li>out of bounds detection only works for off-by-one errors, page-guard vs poison strategy performance difference is non-trivial, but generally page-guards are faster</li>
</ul>
<h1 id="questions-1"><a class="header" href="#questions-1">Questions</a></h1>
<ul>
<li>
<p>Holes in physical memory are either device mapped or reserved, what reserves them?</p>
<ul>
<li>BIOS reserves memory as well</li>
</ul>
</li>
<li>
<p>might the BIOS reserve memory regions? some holes backed by memory. Some should escape memory management logic</p>
</li>
<li>
<p>Why does the kernel have to use virtual memory addresses in the first place can't it just map directly?</p>
<ul>
<li>needs to provide memory separation for clients</li>
</ul>
</li>
<li>
<p>Padding added to zone struct caching?</p>
<ul>
<li>Cache sharing issues for multicore processors. Ping Pong effect can happen.</li>
</ul>
</li>
<li>
<p>Why do we need zones? - tag memory to differentiate for different purposes surface access only software cares about it, but devices might have hardware limitations.</p>
</li>
<li>
<p>Why do we need  pages? - since hardware provided page granularity</p>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="page-tables"><a class="header" href="#page-tables">Page Tables</a></h1>
<p>OS provides virtual memory addresses to processes. Page tables store the translation from virtual addresses to physical addresses and OS gets to decide on this mapping. Virtual addresses are the index to a page table entry in the page table where physical addresses of underlying data are stored. A special register <code>cr3</code> contains physical pointer to first page table. Each page defines an address space which is useful for separating memory for separate processes.</p>
<h3 id="address-spaces"><a class="header" href="#address-spaces">Address spaces</a></h3>
<ul>
<li>Virtualize physical memory can be reused every time</li>
<li>Flexible memory management for continuous memory for example</li>
<li>Provides isolation and separation for separate processes.
<ul>
<li>Shared memory can include same virtual memory for multiple process</li>
<li>threads use shared memory</li>
<li>1 process per 1 page table is typical</li>
<li>Many processes per 1 page table is shared memory</li>
<li>Dynamically linked libraries are loaded into phys mem once</li>
</ul>
</li>
</ul>
<h3 id="linear-page-table"><a class="header" href="#linear-page-table">Linear page table</a></h3>
<ul>
<li>Simple and old design</li>
<li>first 4 bits of Virtual address are index to array of physical offsets</li>
<li>remaining 12 bits are offset within page</li>
<li>1 bit for whether the memory is present or not</li>
</ul>
<h3 id="hierarchical-page-table"><a class="header" href="#hierarchical-page-table">Hierarchical page table</a></h3>
<ul>
<li>first 10 bits are index to level 1 page table containing address of 2nd physical page table</li>
<li>second 10 bits are index to level 2 page table</li>
<li>remaining 12 bits are offset within page</li>
</ul>
<h3 id="inverted-page-tables"><a class="header" href="#inverted-page-tables">Inverted Page tables</a></h3>
<ul>
<li>IA64 (itanic)</li>
<li>using a hash of the virtual memory to store physical address, scales well</li>
</ul>
<h3 id="four-level-page-table"><a class="header" href="#four-level-page-table">Four-level Page Table</a></h3>
<ul>
<li>cr3 contains pointer to PML4 table which is highest level table</li>
<li>Highest bytes on intel aren't used by default Memory Tagging possible, set by sign extended</li>
<li>Virtual address contains:
<ul>
<li>First 16 bits are sign extend or MT Tagging</li>
<li>First 9 bits: PML4 offset</li>
<li>Second 9 bits: Page Directory-Pointer Offset</li>
<li>Third 9 bits: Page Directory Offset</li>
<li>Fourth 9 bits: Page Table Offset</li>
<li>Last 12 bits: Physical Page Offset</li>
</ul>
</li>
</ul>
<h2 id="page-table-entries"><a class="header" href="#page-table-entries">Page Table Entries</a></h2>
<ul>
<li>64 bits, contain bits for if present, writable, supervisor mode, etc...</li>
<li>48bit virtual address and physical address space</li>
<li>Address of large pages:
<ul>
<li>first level PTE doesn't support (512GB) pages</li>
<li>second level PTE supports 1GB Pages</li>
<li>third level PTE supports 2MB Pages</li>
<li>4th PTE only 4K Pages</li>
</ul>
</li>
</ul>
<h2 id="on-boot"><a class="header" href="#on-boot">On Boot</a></h2>
<ul>
<li>asm code loads addresses of the 4 levels depending on how much static memory kernel requires</li>
<li>only static</li>
</ul>
<h2 id="post-boot"><a class="header" href="#post-boot">Post Boot</a></h2>
<ul>
<li>Dynamic, allows page table mappings to change during runtime</li>
<li>Map more pages if more memory is needed</li>
<li>Unmap pages if memory is not needed</li>
<li>What should virtual address space look like in terms of policies?</li>
<li>How are they enforced?</li>
</ul>
<h2 id="virtual-address-space-of-process-p"><a class="header" href="#virtual-address-space-of-process-p">Virtual address space of process P</a></h2>
<ul>
<li>How can we ensure address space of P and P+1 are separate -&gt; page tables</li>
</ul>
<h2 id="meltdown"><a class="header" href="#meltdown">Meltdown</a></h2>
<ul>
<li>Kernel is mapped into higher regions of address space for P, how to make sure P can't access/modify Kernel data?
<ul>
<li>User supervisor bit can be set in PTE, process can't access kernel data despite it being mapped in</li>
<li>Post 2018 Meltdown was able to read kernel data, kernel no longer mapped in address space
<ul>
<li>Kernel now has own page table</li>
<li>on every syscall or Process switch, page tables must be changed, performance impact</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="foreshadow-attack"><a class="header" href="#foreshadow-attack">Foreshadow Attack</a></h2>
<ul>
<li>bypasses the present bit of a PTE, could read pages even if not present</li>
<li>Now we must clear page frame address when un-mapping</li>
</ul>
<h2 id="ridl"><a class="header" href="#ridl">RIDL</a></h2>
<ul>
<li>bypass the address bits - able to read other data</li>
<li>must flush CPU registers to solve</li>
</ul>
<h1 id="page-table-walk"><a class="header" href="#page-table-walk">Page Table Walk</a></h1>
<ul>
<li>Dynamically update page tables for each address space</li>
<li>If a process maps/un-maps in memory, it must be added/removed to address space</li>
<li>MMU uses updated page tables</li>
<li>find page table entry (assume x86_64, 48bit virt addr, page table mapped into virtual memory)</li>
</ul>
<ol>
<li>locate top-level PT (read cr3 register or process struct)</li>
<li>Locate 2nd level PT
<ul>
<li>get virtual pointer to top-level page</li>
<li>use bits 39-47 of virtual address as index</li>
<li>Is the page table entry present? if no, then abort</li>
</ul>
</li>
<li>Locate 3rd level PT
<ul>
<li>get virtual pointer to 2nd level page</li>
<li>use bits 30-38 of virtual address as index</li>
<li>is page table entry present? if no, then abort</li>
</ul>
</li>
<li>...</li>
<li>Last page table entry has physical address of page</li>
</ol>
<h3 id="instructions-to-perform-the-walk-todo"><a class="header" href="#instructions-to-perform-the-walk-todo">Instructions to perform the walk TODO</a></h3>
<ol>
<li>take 9 bits of virt addr, multiply by 8 to get offset and concatenate to bottom 12 bits of cr3.pml4</li>
<li>repeat</li>
</ol>
<h2 id="page-table-mapping"><a class="header" href="#page-table-mapping">Page Table Mapping</a></h2>
<ul>
<li>Input is Virtual address where mapping will take place, do the page table walk to find locate the page table entry</li>
<li>If entry not present at any level, allocate new page, store its physical address in non-present entry, continue with next level</li>
<li>Finally store physical address of page to be mapped in final PTE</li>
</ul>
<h2 id="page-table-unmapping"><a class="header" href="#page-table-unmapping">Page Table Unmapping</a></h2>
<ul>
<li>Locate PTE from virt addr to be unmapped with page table walk</li>
<li>zero out final table entry (Because of Foreshadow attack)</li>
<li>Free the page table (optional)</li>
<li>free the page</li>
</ul>
<h2 id="permission-bits"><a class="header" href="#permission-bits">Permission bits</a></h2>
<ul>
<li>P: page faults (0) or present (1)</li>
<li>R/W: read-only (0) or writable (1)</li>
<li>U/S: Supervisor-only (0) or user-accessible (1)
<ul>
<li>SMAP protection: 1 becomes user-only (follow POLP)</li>
</ul>
</li>
<li>XD: execute allowed (0) or disabled (1)</li>
</ul>
<h2 id="translation-lookaside-buffer-tlb"><a class="header" href="#translation-lookaside-buffer-tlb">Translation Lookaside Buffer (TLB)</a></h2>
<ul>
<li>result of PT translation is a mapping, so we cache the mapping</li>
<li>Hardware based cache that stores memory addresses</li>
<li>Temporal and spatial locality</li>
<li>TLB has very small size, due to implementing LRU</li>
<li>thus, bad temporal and spatial locality will reduce performance</li>
<li>Since TLB is a cache of the page tables, it must be flushed when the Page tables are changed (switching to a new address space) and when explicitly flushing</li>
<li>If TLB not flushed when necessary means disaster</li>
<li>Translation Caches
<ul>
<li>caching PT pages</li>
<li>OS can use bigger pages -&gt; shorter walk on TLB Miss</li>
<li>translation cache tagged with part of virt addr
<ul>
<li>reduce time it takes for a TLB miss</li>
<li>managed transparently by hardware</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="security"><a class="header" href="#security">Security</a></h2>
<ul>
<li>Use page tables to improve sanity checks leave holes and let CPU raise segmentation fault</li>
<li>holes in the identity map, just before and after array add guard page</li>
<li>Pros: no wastage</li>
<li>Cons: more complex management</li>
</ul>
<h3 id="exploits"><a class="header" href="#exploits">Exploits</a></h3>
<ul>
<li>kernels are Highly complex concurrent code (~20M lines of  code)</li>
<li>Physmap in linux is a primary target</li>
<li>kernel base address is a jump target</li>
</ul>
<h3 id="kernel-address-space-layout-randomization-kaslr"><a class="header" href="#kernel-address-space-layout-randomization-kaslr">Kernel Address Space Layout Randomization (KASLR)</a></h3>
<ul>
<li>Randomizes sections in kernel address space</li>
<li>The entire kernel code starts from a random address space
<ul>
<li>brute-forcing leads to crashes</li>
<li>leak kernel pointers, requires second vulnerability</li>
<li>side-channel attacks, very complex to defend</li>
</ul>
</li>
<li>entropy simplified, remains the same until reboot</li>
<li>random slot is chosen early during boot, kernel is mapped there</li>
<li>requires remapping kernel itself as well as its physical memory</li>
<li>use side channels to leak a kernel address</li>
</ul>
<h1 id="questions-2"><a class="header" href="#questions-2">Questions</a></h1>
<ul>
<li>What is in the address field of a PTE?
<ul>
<li>there is a fraction of a physical address along with the page table offset</li>
</ul>
</li>
<li>How much memory can be mapped in x86_64?
<ul>
<li>48 bits to store physical address = 2^40 * 2^8 = 256 Tb</li>
</ul>
</li>
<li>How much memory does a Page in the Page table map?
<ul>
<li>depends whether it is used for large pages, huge or normal pages, but each PTP is 4KB and each PTE is 8 bytes 4096/8 = 512 or 2^12 / 2^3 = 2^9</li>
</ul>
</li>
<li>How to find page table pages?
<ul>
<li>Go through levels of page tables to find entry we want to change.</li>
</ul>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="user-mode"><a class="header" href="#user-mode">User Mode</a></h1>
<p>Any OS will make sure that sys resources can be multiplexed by competing applications. Should happen safely and efficiently. CPU provides support for privileged instructions</p>
<h3 id="privilege-separation"><a class="header" href="#privilege-separation">Privilege Separation</a></h3>
<ul>
<li>
<p>x86 has 4 rings of privilege</p>
<ul>
<li>ring 0: runs kernel, most privileges</li>
<li>ring 1,2: unused</li>
<li>ring 3: user code</li>
</ul>
</li>
<li>
<p>Pointers can be associated either with:</p>
<ul>
<li>Code segments (CS)</li>
<li>Data segments (DS) - heap pointer</li>
<li>Stack Segment (SS) - Local variable pointer</li>
</ul>
</li>
<li>
<p>CS:0x1000 can be different than DS:0x1000</p>
</li>
<li>
<p>However, today all segments point to same memory</p>
</li>
<li>
<p>low-order 2 bits of CS register determine current ring</p>
</li>
<li>
<p>No instruction sets CS register directly</p>
<ul>
<li>From user -&gt; Kernel
<ul>
<li>interrupt CPU ("int" instruction) actually sets CS to 0x00</li>
<li>CPU switches to interrupt handler in kernel (from interrupt table containing functions)</li>
</ul>
</li>
<li>From kernel -&gt; user mode
<ul>
<li>Kernel interrupt handler returns ("iret" instruction)</li>
<li>CPU restores user mode state, including CS</li>
</ul>
</li>
</ul>
</li>
<li>
<p>segments are registers which makes them selectors from a table (GDT)</p>
</li>
</ul>
<h4 id="global-descriptor-table"><a class="header" href="#global-descriptor-table">Global Descriptor Table</a></h4>
<ul>
<li>contains information on segments, code segment selector is an offset into GDT</li>
<li>specifies all the segments and different rings</li>
<li>GDTR register points to the GDT</li>
<li>DPL Field decides which ring can access memory</li>
</ul>
<h1 id="task-struct-linux"><a class="header" href="#task-struct-linux">Task struct (linux)</a></h1>
<ul>
<li>Task is a generalization of a process and a thread</li>
<li>contains pid, parent_pid, frame of registers and pointer to page_table</li>
<li>contains a specific state, stack pointer, which cpu, memory management, credentials, open files that process can access</li>
</ul>
<h1 id="security-1"><a class="header" href="#security-1">Security</a></h1>
<ul>
<li>
<p>Meltdown</p>
<ul>
<li>speculative code reads data into cache</li>
<li>KPTI Kernel Page Table Isolation, performance hit</li>
</ul>
</li>
<li>
<p>Foreshadow</p>
<ul>
<li>PTE address bits must also be cleared</li>
</ul>
</li>
<li>
<p>RIDL</p>
<ul>
<li>bypasses the address bits</li>
<li>ver instruction flushes address</li>
<li>SMEP - supervisor mode execution protection (always on)</li>
<li>SMAP - supervisor mode access protection (copy_to / from_user) - specific instructions exist to temporarily disable SMAP</li>
</ul>
</li>
<li>
<p>Defending Kernel Attacks: prevent kernel vulnerabilities from directing control flow to user land code by enabling SMAP Supervisor Mode Access Protection</p>
</li>
<li>
<p>ASLR: user process randomization</p>
<ul>
<li>linux mmap provides 28 bits of entropy</li>
</ul>
</li>
</ul>
<h1 id="questions-3"><a class="header" href="#questions-3">Questions</a></h1>
<ul>
<li>Where does it store user mode state?</li>
<li>Where is GDT stored and who is responsible for it?</li>
<li>What is the minimum of kernel code needed to map into a process? interrupt handler and sys calls, kernel stack, trampoline to kernel.</li>
<li>How can processes have different privilege levels? - Task structs can add another level of privileges between user processes.</li>
<li>If user code is no-pie, you can still always randomize the stack and heap.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="interrupts"><a class="header" href="#interrupts">Interrupts</a></h1>
<p>An event that interrupts the execution flow of the kernel. It gets handled by the kernel before the program execution can continue. From the perspective of the CPU they can either be <em>external</em> - (key presses, network packets) or <em>internal</em> - (divide by zero, page fault).</p>
<h3 id="terminology-intel-based"><a class="header" href="#terminology-intel-based">Terminology (Intel based)</a></h3>
<ul>
<li>
<p>Interrupt (something needs handling)</p>
<ul>
<li>External:
<ul>
<li>Hardware generated, a device triggers the interrupt through a pin on the CPU, masking allows to postpone consecutive interrupts (only kernel can set masks)</li>
</ul>
</li>
<li>Internal - Software generated, software needs something form kernel - opening a file, allocating memory, any system call (<code>int n</code> defines the type of interrupt where n is 1 byte)</li>
</ul>
</li>
<li>
<p>Exception (something went wrong)</p>
<ul>
<li>Fault - error condition (/0, page fault...) instruction can be retried</li>
<li>Trap - Typically for debugging (breakpoint, overflow) program can resume</li>
<li>Abort - serious error condition that is unrecoverable, process cannot continue (double fault or unrecoverable hardware error)</li>
</ul>
</li>
<li>
<p>Interrupt handling systems handles exceptions as well</p>
</li>
<li>
<p>Asynchronous vs Synchronous interrupts</p>
<ul>
<li>most software interrupts are synchronous - kernel can handle specific to the instruction</li>
<li>most hardware interrupts are asynchronous - can come at any time, masking must be done</li>
</ul>
</li>
</ul>
<h3 id="privilege"><a class="header" href="#privilege">Privilege</a></h3>
<ul>
<li>Interrupt handlers run at high privilege level, but are handled in ring 0</li>
</ul>
<h3 id="interrupt-procedure"><a class="header" href="#interrupt-procedure">Interrupt Procedure</a></h3>
<ol>
<li>CPU elevates privilege level and switches to kernel stack (unless already in kernel)</li>
<li>User context is saved so that program can resume again</li>
<li>The interrupt's service routine is called</li>
<li>CPU restores some of the user context and drops the privilege level</li>
</ol>
<h3 id="idt-interrupt-descriptor-table"><a class="header" href="#idt-interrupt-descriptor-table">IDT Interrupt Descriptor Table</a></h3>
<ul>
<li>Max 256 entries</li>
<li>first 32 entries reserved exceptions</li>
<li>16 external hardware interrupts can be remapped using APIC unit</li>
<li>IDTR (R for register) contains IDT Base Address + IDT Limit</li>
<li>Interrupt vector identifies type of interrupt</li>
<li>look up interrupt gate in IDT using vector</li>
<li>Jump to interrupt handler and ring 0</li>
<li>Mask further instr</li>
<li>Switch stack</li>
<li>Store calling context</li>
</ul>
<h3 id="trap-vs-interrupt"><a class="header" href="#trap-vs-interrupt">Trap vs Interrupt</a></h3>
<ul>
<li>Interrupt will mask further interrupts</li>
<li>Trap (exception) will not mask</li>
</ul>
<h3 id="restoring-the-kernel-stack"><a class="header" href="#restoring-the-kernel-stack">Restoring the Kernel stack</a></h3>
<ul>
<li>TSS Task State Segment</li>
<li>TR Task Register</li>
<li>TSS contains stack pointers for each ring</li>
</ul>
<h3 id="returning"><a class="header" href="#returning">Returning</a></h3>
<ul>
<li>special <code>iret</code> returns all the state for the user process and makes sure the CS is set back to the right privilege</li>
</ul>
<h3 id="livelocks"><a class="header" href="#livelocks">Livelocks</a></h3>
<ul>
<li>Too many interrupts will cause the CPU to deal with nothing else.</li>
<li>should try do as little in the handling routine as possible</li>
<li>reduce number of interrupts</li>
<li>offload to hardware</li>
<li>switch to polling vs handling</li>
<li>hardware DMA, forego interrupts</li>
</ul>
<h1 id="questions-4"><a class="header" href="#questions-4">Questions</a></h1>
<ul>
<li>Are software interrupts considered strictly internal interrupts?</li>
<li>Where in memory is IDT?</li>
<li>Who sets IDTR?</li>
<li>Where is interrupt code in memory?</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="system-calls"><a class="header" href="#system-calls">System Calls</a></h1>
<p>Interrupts raised by software, a demand by a process requesting the kernel to do something.
Originally, it was just <code>int 0x80</code>, nowadays there are more optimized <code>syscall</code> instructions. User and Kernel code abide by calling convention to put the syscall number into %rax, and arguments are specified into specific registers (<code>rdi, %rsi, %rdx, %r10, %r8, %r9</code>). Kernel places return value into <code>%rax</code>.</p>
<h3 id="performance-of-syscalls"><a class="header" href="#performance-of-syscalls">Performance of Syscalls</a></h3>
<ul>
<li>IDT entry cached in CPU register to avoid cache misses.</li>
</ul>
<h1 id="questions-5"><a class="header" href="#questions-5">Questions</a></h1>
<p>Why exactly is there a pipeline performance issue?</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="page-faults"><a class="header" href="#page-faults">Page Faults</a></h2>
<p>A special kind of exception from interrupt vector 14 where the MMU is indicating it wants attention of the OS. On demand paging relies on page faults.</p>
<ul>
<li><strong>Invalid</strong> - Access to an invalid page (write to a read only page)</li>
<li><strong>Major</strong> - Access is valid, but page is no in memory usually takes a longer amount of time to resolve(file or swapped pages)</li>
<li><strong>Minor</strong> - Access is valid and page is in memory, latency usually small (first access to anonymous memory)</li>
</ul>
<h3 id="terms"><a class="header" href="#terms">Terms</a></h3>
<ul>
<li>Anonymous Memory - Memory that is not backed by files on the disk such as stack &amp; heap</li>
<li>File backed Memory - Code pages loaded from disk</li>
<li>Faulting address - the address that caused the page fault</li>
</ul>
<h3 id="kernel-page-faults"><a class="header" href="#kernel-page-faults">Kernel Page faults</a></h3>
<ul>
<li>
<p>Invalid</p>
<ul>
<li>faulting address is Kernel address: oops! kernel bug cause panic</li>
<li>faulting address is User address: checks (linux's copy_to / from_user)</li>
</ul>
</li>
<li>
<p>Major faults - if kernel is paged out (doesn't happen since linux is always mapped out)</p>
<ul>
<li>downsides - very complex, can be dangerous</li>
<li>upsides - for memory hungry OSes, windows kernel development is run by marketing team and budget vs linux kernel dev is bottom up - reduce complexity vs increasing complexity</li>
</ul>
</li>
<li>
<p>Minor faults - lazy allocations (not anymore)</p>
</li>
</ul>
<blockquote>
<p>Aside - huge pages were pushed heavily by cloud companies top down into linux kernel vs in windows top down is the common case</p>
</blockquote>
<h3 id="user-page-fault"><a class="header" href="#user-page-fault">User Page fault</a></h3>
<ul>
<li>for the user, anything goes!</li>
<li>faulting address space in mm struct</li>
<li>How to figure out what went wrong?</li>
<li>cr2 register contains faulting address</li>
</ul>
<h3 id="fault-info---how-to-retrieve-information"><a class="header" href="#fault-info---how-to-retrieve-information">Fault info - how to retrieve information</a></h3>
<ul>
<li>
<p>HW - SW contract, faulting address must be in CR2 register, pushes a 32bit code on the stack for error code encoding</p>
</li>
<li>
<p>| I | R | U | W | P |</p>
</li>
<li>
<p>P - set if pte was present</p>
</li>
<li>
<p>W - set if page cased by write access</p>
</li>
<li>
<p>U - were in User mode</p>
</li>
<li>
<p>R - had reserved bits set (more advanced)</p>
</li>
<li>
<p>I - was an instruction fetch access</p>
</li>
<li>
<p>Get user thread that "holding thread" that made the access <code>get_current().task</code></p>
</li>
<li>
<p>How to implement get_current()</p>
</li>
<li>
<p>on X86 reads from per CPU pointer <code>DECLARE_PER_CPU</code> form gs segment keep one segment in memory around, they are all one to one. Then, gs must point to the right memory for the task</p>
</li>
</ul>
<blockquote>
<p>kernel mappings must get duplicated in on the memory mapping for every task, typically only over the 256 pml4 entries that matter</p>
</blockquote>
<blockquote>
<p>If we need thread local space (tls) we need a register, can't be pinned to memory</p>
</blockquote>
<h3 id="page-faults-1"><a class="header" href="#page-faults-1">Page Faults</a></h3>
<ul>
<li>
<p>VMA info - don't store page table information in vma_area_struct to get faulting address walk page tables to get faulting address</p>
</li>
<li>
<p>Splitting VMAs if they have the same properties</p>
</li>
</ul>
<h2 id="virtual-memory-area-vma"><a class="header" href="#virtual-memory-area-vma">Virtual Memory Area (VMA)</a></h2>
<p>Contiguous regions of virtual memory with given properties. Typically, for on demand paging, only vmas are allocated to a given process, but underlying pages for that memory are not mapped. Only upon a Pagefault of a given requested address will the page be allocated.</p>
<h2 id="questions-6"><a class="header" href="#questions-6">Questions</a></h2>
<ul>
<li>what does it mean to be anonymous vs file backed?</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="multiprocessing"><a class="header" href="#multiprocessing">Multiprocessing</a></h1>
<h3 id="fork"><a class="header" href="#fork">Fork</a></h3>
<ul>
<li>
<p>creates a new child process by duplicating calling process</p>
</li>
<li>
<p>built on top of clone() syscall</p>
</li>
<li>
<p>Copy most information, allocate and init new kernel stack and some others like:</p>
<ul>
<li>copy_files</li>
<li>copy_fs</li>
<li>copy_sighand</li>
<li>copy_signal</li>
<li>copy_mm - dup_mm and dup_mmap, which will copy vma information and page tables (requires fixing)
<ul>
<li>for pages that are R/W, kernel implements Copy on Write (COW) which sets one read-only page frame for both processes and on every page write, the PF handler copies the new page</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="exec"><a class="header" href="#exec">Exec</a></h3>
<ul>
<li>executes the program pointed by a filename</li>
<li>implementation:
<ul>
<li>input and permission</li>
<li>load binary headers in memory</li>
<li>find bin format - <em>there are other formats that linux supports other than ELF...</em></li>
<li>flush old resources</li>
</ul>
</li>
<li>Load binary</li>
<li>Page tables initially empty</li>
</ul>
<h4 id="copy-on-write-applications"><a class="header" href="#copy-on-write-applications">Copy On Write Applications</a></h4>
<ul>
<li>file pages
<ul>
<li>deduplicate binary pages for unrelated processes</li>
<li>many pages (text) pages are never written to COWed</li>
</ul>
</li>
<li>anon forked pages
<ul>
<li>deduplicate pages within process hierarchy</li>
<li>many (fork+exec) never COWed</li>
<li>typically fork + exec are called right after, with COW fork doesn't duplicate all page frames in address space which would be wasted on exec call</li>
</ul>
</li>
<li>anon zero pages
<ul>
<li>deduplicates zero pages for unrelated processes</li>
<li>at first read PF, map single read-only (global) zero page</li>
<li>COW at first write PF
<ul>
<li>if processes read anon pages only, this is a win</li>
<li>if processes write, this is a loss (2 page faults instead of one)</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="scheduling"><a class="header" href="#scheduling">Scheduling</a></h2>
<ul>
<li>simple version: preemptive round robin schedule with no priorities, simply schedule all available processes and use a queue (FIFO)</li>
</ul>
<h3 id="time-management"><a class="header" href="#time-management">Time Management</a></h3>
<ul>
<li>Clock circuits:
<ul>
<li>expose counters incremented at given frequency</li>
<li>can be used for precise time measurements</li>
</ul>
</li>
<li>Timer circuits:
<ul>
<li>issue periodic interrupts at given frequency</li>
<li>can be used for scheduling</li>
</ul>
</li>
<li>RTC - real time clock
<ul>
<li>second granularity, but battery powered</li>
</ul>
</li>
</ul>
<h4 id="clock-event-devices"><a class="header" href="#clock-event-devices">Clock event devices</a></h4>
<ul>
<li>programmed to issue interrupts at CONFIG_HZ frequency, timer interrupts aka. ticks</li>
<li>Both user and kernel preemption are possible</li>
<li>choosing frequency is a balance between smooth operation for user and too much overhead for each interrupt</li>
<li>interrupts are useful to interrupt software, and they "preempt software"
<ul>
<li>from the kernel's perspective you want to preempt the user</li>
<li>can also preempt kernel - preemptive kernel</li>
</ul>
</li>
</ul>
<h4 id="at-each-tick"><a class="header" href="#at-each-tick">At each tick:</a></h4>
<pre><code class="language-c">jiffies_64++; // update ticks since startup
update_wall_time(); // update current date/time
update_process_times(); // accounting
profile_tick(); 

while (time_after_eq(jiffies, base-&gt;clk))
    expire_times(base, ... ) // expired timers

schedule(); // invoke the scheduler
</code></pre>
<h1 id="scheduling-1"><a class="header" href="#scheduling-1">Scheduling:</a></h1>
<ul>
<li>State: associated to a given task <code>RUNNING, RUNNABLE, SLEEPING</code></li>
<li>Quantum / time slice
<ul>
<li>max number of jiffies a task can run on a CPU</li>
<li>initialized with a task-specific formula</li>
<li>Decremented at every tick, task is done at 0</li>
<li>sufficient to ensure fairness for CPU-intensive tasks</li>
<li><em>fairness</em> - each process gets the same CPU time (not the case for I/O intensive tasks)</li>
</ul>
</li>
<li>Priority
<ul>
<li>initialized with static (predetermined) priority</li>
<li>possibly adjusted periodically (based on behavior of task)</li>
</ul>
</li>
<li>Scheduling policy
<ul>
<li>NORMAL, BATCH, IDLE -&gt; completely fair scheduler</li>
</ul>
</li>
</ul>
<h3 id="tickless-kernel"><a class="header" href="#tickless-kernel">Tickless Kernel</a></h3>
<ul>
<li>ticked kernel has issue of balance between (+responsive, -overhead) finding a sweet spot is hard</li>
<li>tickless design uses a sw timer for the "end of quantum event"</li>
<li>reprogram hardware at every tick to tick next when the next timer expires (non-constant duration between ticks)</li>
<li>NO_HZ_IDLE tickless when idle</li>
<li>FULL go tickless when 1 task is running</li>
</ul>
<h3 id="linux-o1-scheduler"><a class="header" href="#linux-o1-scheduler">Linux O(1) Scheduler</a></h3>
<ul>
<li>preemptive (will preempt user execution) round-robin (queues) priority scheduler</li>
<li>Maintains N run queues (1 per priority level)
<ul>
<li>find highest priority queue with runnable task</li>
<li>find the task on that queue and deq it</li>
<li>calc its time slice based  on prio. and <code>run</code></li>
<li>when its time is up, enqueue it and repeat</li>
</ul>
</li>
<li>improving fairness
<ul>
<li>priorities are adjusted based on sleep time</li>
<li>I/O bound processes tend to have higher priority, since the will give up CPU for I/O and thus get less actual CPU time, typically they are user-facing</li>
</ul>
</li>
<li>Why O(1) - bc all operations are constant time, no loop across tasks, scales well
<ul>
<li>finds first bit set in bit map</li>
</ul>
</li>
</ul>
<h3 id="linux-cfs-schedule"><a class="header" href="#linux-cfs-schedule">Linux CFS Schedule</a></h3>
<ul>
<li>O(1) used hard-to-maintain hacks for fairness - code got unmaintainable, too hacky</li>
<li>CFS: Tasks get a "completely fair" CPU share
<ul>
<li>record how much CPU time each task has been given</li>
<li>schedule task with biggest delta to tot_</li>
<li>virtual runtime to deal with priorities</li>
<li>increase virtual runtime faster for lower-priority tasks</li>
</ul>
</li>
<li>no heuristics to distinguish tasks</li>
<li>no run queues, uses red-black tree</li>
</ul>
<h1 id="inter-process-communication-ipc"><a class="header" href="#inter-process-communication-ipc">Inter Process Communication (IPC)</a></h1>
<ul>
<li>
<p>System V vs POSIX differences</p>
<ul>
<li>System V original UNIX implementation +compatibility</li>
<li>POSIX was standardized later +user-friendly +features</li>
</ul>
</li>
<li>
<p>mmap MAP_SHARED only works for processes within the same hierarchy</p>
</li>
<li>
<p>mmap MAP_SHARED could be used for processes outside of the hierarchy if they are file backed (not ideal)</p>
</li>
</ul>
<h3 id="shared-memory-sysv"><a class="header" href="#shared-memory-sysv">Shared Memory (SysV)</a></h3>
<ul>
<li>irrelevant which processes are using shared memory, don't have to be part of same process hierarchy</li>
<li>all processes should share them same page frames</li>
<li>int shmget(key, size, shmflag)</li>
<li>attach / detach segment shmid</li>
</ul>
<h3 id="message-queues-sysv"><a class="header" href="#message-queues-sysv">Message Queues (SysV)</a></h3>
<ul>
<li>Also provide 1. data exchange and 2. synchronized exchange (works on top of shared mem)</li>
<li>Wants to reliably send message to another process</li>
<li>Sending task will copy message to message queue's memory area</li>
<li>Receiving task will copy message from queue into its own memory area</li>
<li>all are done through blocking system calls</li>
<li>queue is size limited by construction, so send/recv calls will block</li>
<li>properties: not stream oriented, supports random queue access, bidirectional, always named</li>
</ul>
<h3 id="posix-ipc-difference"><a class="header" href="#posix-ipc-difference">POSIX IPC: difference</a></h3>
<ul>
<li>uses names not keys</li>
<li>uses reference counting easier to deallocate</li>
<li>provides thread safety</li>
<li>shared memory is file oriented</li>
</ul>
<h1 id="tmpfs"><a class="header" href="#tmpfs">tmpfs</a></h1>
<ul>
<li>shared memory was made available through the different backings (Sys V, mmap(MAP_SHARED), POSIX)</li>
<li></li>
</ul>
<h1 id="questions-7"><a class="header" href="#questions-7">Questions</a></h1>
<ul>
<li>What routines should preempt the kernel?</li>
<li>In what cases does a "preemptive" kernel make sense?</li>
<li>What about "real-time" kernels?</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="multicore"><a class="header" href="#multicore">Multicore</a></h1>
<ul>
<li>Dennard's Scaling - <code>P = NCFV^2 + VL</code></li>
<li>Power decides what you can do in your chip</li>
<li>Moore's law would lower the size of C, so you could increase the frequency or have more transistors</li>
<li>Post-Dennard Era (2005-Now)</li>
<li>Do not increase frequency</li>
<li>More hardware features - GPU/NIC/FPGA</li>
<li>Instruction set extensions</li>
</ul>
<h3 id="multicores"><a class="header" href="#multicores">Multicores</a></h3>
<ul>
<li>Explicit parallel execution</li>
<li>Cores share resources:
<ul>
<li>caches</li>
<li>memory</li>
<li>IO</li>
<li>System Interconnect</li>
</ul>
</li>
</ul>
<h3 id="turning-on-x86-cores"><a class="header" href="#turning-on-x86-cores">Turning on X86 Cores</a></h3>
<ul>
<li>one bootstrapping processor</li>
<li>bios sets it up in a predefined memory region</li>
<li>used to discover and configure carious hradware components</li>
<li>locate the right data</li>
<li>PICs aren't used anymore, (local) APIC replaced
<ul>
<li>localapic is in same memory for each processor since it's local</li>
</ul>
</li>
</ul>
<h3 id="starting-aps-application-processors"><a class="header" href="#starting-aps-application-processors">Starting APs (Application Processors)</a></h3>
<ul>
<li>Send init Inter Processor Interrupt</li>
<li>send start-up IPI</li>
<li>manage per-core kernel stack</li>
</ul>
<h3 id="end-of-multicore"><a class="header" href="#end-of-multicore">End of multicore</a></h3>
<ul>
<li>End of multicore scaling also due to a heat problem where switching cores</li>
<li>solution is to turn of lots of cores</li>
<li>specialized cores</li>
<li>Turn cores on/off cores quickly</li>
</ul>
<h3 id="dealing-with-concurrency"><a class="header" href="#dealing-with-concurrency">Dealing with Concurrency</a></h3>
<ul>
<li>Each core has its own kernel</li>
<li>data structures need to be shared and in a consistent state</li>
<li>Solutions:
<ul>
<li>lock the state (performance problems)
<ul>
<li>spinlocks</li>
<li>mutexes</li>
<li>Read-copy-update (RCU)
<ul>
<li>use replication to make locks scalable</li>
<li>contention on a single pointer and if there is write, expensive copy</li>
</ul>
</li>
</ul>
</li>
<li>partition the state (underutilization)</li>
<li>replicate it (stale state)</li>
</ul>
</li>
<li>start with locking, if performance becomes unbearable, try a different way</li>
</ul>
<h3 id="bkl"><a class="header" href="#bkl">BKL</a></h3>
<ul>
<li>simple and minimally complex</li>
<li>cons: kernel execution becomes serialized</li>
</ul>
<h3 id="fine-grained-locking"><a class="header" href="#fine-grained-locking">Fine-grained locking</a></h3>
<ul>
<li>start with BKL and make locks smaller and smaller</li>
<li>lock only each subsystem</li>
<li>keep making locks finer and finer such that locks don't take up too much CPU</li>
</ul>
<h3 id="multicore-parallelism"><a class="header" href="#multicore-parallelism">Multicore Parallelism</a></h3>
<ul>
<li>needs multiple threads of execution</li>
<li>user-mode applications can spawn threads
<ul>
<li>kernel schedules user-mode threads on top of idle core</li>
</ul>
</li>
<li>parallelism for kernel tasks
<ul>
<li>post-interrupt work</li>
<li>background maintenance</li>
<li>filling up per-CPU frame caches</li>
<li>writing dirty data to disk</li>
<li>RCU garbage collection</li>
</ul>
</li>
<li>Interrupt handlers do as little as possible <em>"top half"</em></li>
<li>Deferred handling in interrupt execution context
<ul>
<li>no active process, no sleeping just spinlocks</li>
</ul>
</li>
<li>Process execution context
<ul>
<li>workqueues / kernel threads</li>
<li>active process</li>
<li>sleep allowed, mutex possible</li>
</ul>
</li>
</ul>
<h3 id="bottom-halves"><a class="header" href="#bottom-halves">Bottom Halves</a></h3>
<ul>
<li>enqueue interrupt handling</li>
<li>execute before returning to user mode</li>
<li>only on BH at a time</li>
<li>inefficient due to lack of parallelism
<ul>
<li>now obsolete</li>
<li>replaced by softIRQs and tasklets</li>
</ul>
</li>
</ul>
<h3 id="softirq-vs-tasklets---modern-approach-to-bottom-halves"><a class="header" href="#softirq-vs-tasklets---modern-approach-to-bottom-halves">SoftIRQ vs Tasklets - modern approach to Bottom Halves</a></h3>
<ul>
<li>SoftIRQs
<ul>
<li>multiple instances of softirq run concurrently</li>
<li>very efficient hard to program</li>
<li>limited number available (32)</li>
<li>High priority work (separated by priority)</li>
<li>run concurrently on multiple CPUs</li>
<li>Per-CPU bitmask of softirqs needing work</li>
</ul>
</li>
<li>Tasklets
<ul>
<li>multiple tasklets run concurrently, but just one instance of each</li>
<li>less concurrency, easier to program</li>
<li>implemented on top of softirqs</li>
<li>can dynamically register more</li>
</ul>
</li>
<li>Linux Workqueues
<ul>
<li>softirqs and tasklets run in interrupt execution context</li>
<li><code>ps aux | grep kworkers</code></li>
</ul>
</li>
<li>Linux Kernel Threads
<ul>
<li>Unit of parallelism in the kernel</li>
<li>use the wait-queue mechanism to get notified of jobs</li>
</ul>
</li>
</ul>
<h1 id="questions-8"><a class="header" href="#questions-8">Questions</a></h1>
<ul>
<li>
<p>How do you decide whether to turn a core off?</p>
<ul>
<li>which core? - thermals of neighbors</li>
<li></li>
</ul>
</li>
<li>
<p>How do you decide whether to turn a core back on?</p>
<ul>
<li>if number of tasks increases / load increases</li>
</ul>
</li>
<li>
<p>Which multicore performance enhancements interfere?</p>
<ul>
<li>replication of data structures</li>
<li>requires a global view and migration</li>
</ul>
</li>
<li>
<p>what can be done when there is heavy contention on a VMA for user allocation</p>
<ul>
<li>partition part of the memory to use core-local data structures for memory allocaitons</li>
</ul>
</li>
<li>
<p>For what kind of systems are these most suitable</p>
<ul>
<li>
<p>explicit sharing</p>
</li>
<li>
<p>barrelfish - heterogeneous CPUs</p>
</li>
<li>
<p>Many core, NUMA/non cache coherent</p>
</li>
</ul>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="hardware-security"><a class="header" href="#hardware-security">Hardware Security</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="dram"><a class="header" href="#dram">DRAM</a></h1>
<ul>
<li>Dynamic Random Access Memory</li>
<li>Organized in memory cells with 1-bit data</li>
<li>Charge/Discharge capacitor requires refresh due to charge leak</li>
<li>DRAM organization (aka "geometry"):
<ul>
<li>Channel - Some bits address which channel, each channel has a memory bus (data/control are separated) offers bus-level parallelism (128 bits per transfer)</li>
<li>DIMM - Some bits address which DIMM</li>
<li>Rank - Which <em>"side"</em> of the DIMM, can work independently, at any time only one rank can be active, over the bus requests are sent/seen by all ranks and only selected rank will react to request</li>
<li>Chips - all chips on a rank are active during memory request "8x" Chips require 8 chips, since each does 8 bits for a 64 bit total.</li>
<li>Banks - Spans all chips - addressed by some bits</li>
<li>Rows - Rows in each bank - addressed by some bits</li>
<li>Columns - addressed by some bits</li>
</ul>
</li>
<li>Capacity = rows x columns x bytesPerColumn x banks x chips x ranks x DIMMs</li>
<li>RowSize = columns x bytesPerColumn x Chips</li>
</ul>
<h2 id="read"><a class="header" href="#read">Read</a></h2>
<ol>
<li>RowBuffer = logically spans all chips data from row gets "moved destructively" from row into rowBuffer</li>
<li>8 requests to read one cache line - read rowBuffer byte-by-byte</li>
<li>Write rowBuffer back into row
<ul>
<li>When does rowBuffer get written back into row?</li>
<li>Open-row policy: <em>MC expects more hits on the same row</em>
<ul>
<li>row kept open, optimizing for access locally</li>
<li>we expect cheap row buffer hits</li>
<li>but misses are more costly (need precharge)</li>
</ul>
</li>
<li>Close-row policy: <em>MC expects requests for different rows</em>
<ul>
<li>precharge after access, optimizing for little locality</li>
<li>we expect misses, eliminate precharge latency</li>
</ul>
</li>
<li>MCs use proprietary policies, along with undocumented policies
<ul>
<li>(want to improve bank-level parallelism)</li>
</ul>
</li>
</ul>
</li>
</ol>
<h2 id="address-mapping"><a class="header" href="#address-mapping">Address Mapping</a></h2>
<ul>
<li>physical address space != dram address space</li>
<li>MC decides the mapping between physical addresses to dram addresses</li>
<li>complex xor functions on all recent CPUs</li>
<li>Mapping has an impact on performance <em>trade secret!</em></li>
<li>Knowing mapping has security applications <em>dram side side channels!</em></li>
</ul>
<h2 id="proprietary-knowledge"><a class="header" href="#proprietary-knowledge">Proprietary Knowledge:</a></h2>
<ul>
<li>MC
<ul>
<li>policies: precharge, refresh, scheduling</li>
<li>data encoding on the bus (ECC bits)</li>
<li>physical -&gt; dram address mapping</li>
</ul>
</li>
<li>DRAM might internally change row address mapping
<ul>
<li>improve routing on the board</li>
<li>blacklist bad rows</li>
<li>figuring this out is an open problem</li>
</ul>
</li>
</ul>
<h2 id="side-channel-with-rowbuffers"><a class="header" href="#side-channel-with-rowbuffers">Side Channel with RowBuffers</a></h2>
<ul>
<li>Reading data from non-activated rows will be slow</li>
<li>Can find whether row was active or not based on this side channel</li>
</ul>
<h2 id="timing-attacks"><a class="header" href="#timing-attacks">Timing Attacks</a></h2>
<ul>
<li>Pros
<ul>
<li>not labour intensive</li>
<li>special equipment not necessary</li>
<li>can be done remotely</li>
</ul>
</li>
<li>Cons
<ul>
<li>cannot look at data its</li>
<li>cannot easily reconstruct address selection functions precisely</li>
</ul>
</li>
<li>spy on victim core (repeated check for bank conflicts to detect victim accesses to that bank)</li>
</ul>
<h2 id="bus-probing"><a class="header" href="#bus-probing">Bus Probing</a></h2>
<ul>
<li>Pros:
<ul>
<li>precise</li>
<li>analyze one bit at a time with different addresses</li>
<li>can look at both address and data bits</li>
</ul>
</li>
<li>Cons:
<ul>
<li>labour-intensive</li>
<li>expensive equipment</li>
</ul>
</li>
</ul>
<h1 id="questions-9"><a class="header" href="#questions-9">Questions</a></h1>
<ul>
<li>Why is there a distinction between chips and banks (chips aren't addressed in the physical address)?</li>
<li>Are there any relations to CPU optimizations to memory access patterns in DIM?</li>
</ul>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js"></script>
        <script src="mark.min.js"></script>
        <script src="searcher.js"></script>

        <script src="clipboard.min.js"></script>
        <script src="highlight.js"></script>
        <script src="book.js"></script>

        <!-- Custom JS scripts -->

        <script>
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>

    </div>
    </body>
</html>
